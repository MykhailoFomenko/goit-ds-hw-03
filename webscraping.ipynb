{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://quotes.toscrape.com/\"\n",
    "\n",
    "def get_texts():\n",
    "    html_doc = requests.get(URL)\n",
    "    soup = BeautifulSoup(html_doc.text, \"html.parser\")\n",
    "    text_list = []\n",
    "\n",
    "    content = soup.select(\"div[class=row] div[class=col-md-8] div[class=quote] span[class=text]\")\n",
    "    for el in content:\n",
    "        el = str(el)\n",
    "        reg = re.search(r'“\\D+”', el)\n",
    "        if reg == None:\n",
    "            text_list.append(el[35:-7])\n",
    "        else:\n",
    "            text_list.append(reg.group())\n",
    "\n",
    "    return text_list\n",
    "\n",
    "\n",
    "def get_tags():\n",
    "    html_doc = requests.get(URL)\n",
    "    soup = BeautifulSoup(html_doc.text, \"html.parser\")\n",
    "    tags_list = []\n",
    "\n",
    "    content = soup.select(\"div[class=row] div[class=col-md-8] div[class=quote] div[class=tags]\")\n",
    "    for el in content:\n",
    "        tags_for_one = []\n",
    "        for i in el:\n",
    "            i = str(i)\n",
    "            if 'class=\"tag\"' in i:\n",
    "                tags_for_one.append(re.search(r\">\\D+<\", i).group()[1:-1])\n",
    "        tags_list.append(tags_for_one)\n",
    "    return tags_list\n",
    "\n",
    "\n",
    "def get_autors():\n",
    "    html_doc = requests.get(URL)\n",
    "    soup = BeautifulSoup(html_doc.text, \"html.parser\")\n",
    "    autors_list = []\n",
    "\n",
    "    content = soup.select(\"div[class=row] div[class=col-md-8] div[class=quote] small[class=author]\")\n",
    "    for el in content:\n",
    "        el = str(el)\n",
    "        autors_list.append(re.search(r\">\\D+<\", el).group()[1:-1])\n",
    "\n",
    "    return autors_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = []\n",
    "\n",
    "index = 0\n",
    "for quote in get_texts():\n",
    "    dict_with_info = dict()\n",
    "    dict_with_info[\"tags\"] = get_tags()[index]\n",
    "    dict_with_info[\"author\"] = get_autors()[index]\n",
    "    dict_with_info[\"quote\"] = quote\n",
    "    all.append(dict_with_info)\n",
    "    index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"qoutes.json\", \"w\", encoding=\"utf=8\") as f:\n",
    "    json.dump(all, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_list():\n",
    "    html_doc = requests.get(URL)\n",
    "    soup = BeautifulSoup(html_doc.text, \"html.parser\")  \n",
    "    url_list = []\n",
    "\n",
    "    content = soup.select(\"div[class=container] div[class=row] div[class=col-md-8] div[class=quote] span a\") \n",
    "    for link in content:\n",
    "        reg = re.search(r\"\\D+\", link['href']).group()   \n",
    "        url_list.append(reg)\n",
    "\n",
    "    return url_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = []\n",
    "\n",
    "for link in get_url_list():\n",
    "    html_doc = requests.get(URL + link)\n",
    "    soup = BeautifulSoup(html_doc.text, \"html.parser\")\n",
    "    dict_for_one = dict()\n",
    "\n",
    "    content = soup.select(\"div[class=container] div[class=author-details]\")\n",
    "    for el in content:\n",
    "        dict_for_one[\"fullname\"] = el.find(\"h3\", attrs={\"class\" : \"author-title\"}).text\n",
    "        dict_for_one[\"born_date\"] = el.find(\"span\", attrs={\"class\" : \"author-born-date\"}).text\n",
    "        dict_for_one[\"born_location\"] = el.find(\"span\", attrs={\"class\" : \"author-born-location\"}).text\n",
    "        dict_for_one[\"description\"] = str(el.find(\"div\", attrs={\"class\" : \"author-description\"}).text).strip()\n",
    "    \n",
    "    all.append(dict_for_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"authors.json\", \"w\", encoding=\"utf=8\") as f:\n",
    "    json.dump(all, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
